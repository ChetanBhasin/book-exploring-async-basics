<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Investigating Async Basics - Implementing the Node.js Eventloop in Rust</title>
        
        <meta name="robots" content="noindex" />
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body class="light">
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            document.body.className = theme;
            document.querySelector('html').className = theme + ' js';
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="affix"><a href="introduction.html">Introduction</a></li><li><a href="1_what_is_async.html"><strong aria-hidden="true">1.</strong> What is async?</a></li><li><a href="2_async_history.html"><strong aria-hidden="true">2.</strong> Async history</a></li><li><a href="3_0_the_operating_system.html"><strong aria-hidden="true">3.</strong> The Operating System and CPU</a></li><li><ol class="section"><li><a href="3_1_communicating_with_the_os.html"><strong aria-hidden="true">3.1.</strong> Communicating with the OS</a></li><li><a href="3_2_the_cpu_and_the_os.html"><strong aria-hidden="true">3.2.</strong> The CPU and the OS</a></li></ol></li><li><a href="4_interrupts_firmware_io.html"><strong aria-hidden="true">4.</strong> Interrupts, Firmware and I/O</a></li><li><a href="5_strategies_for_handling_io.html"><strong aria-hidden="true">5.</strong> Strategies for handling I/O</a></li><li><a href="6_0_implementing_the_node_eventloop.html"><strong aria-hidden="true">6.</strong> Implementing the Node Eventloop</a></li><li><ol class="section"><li><a href="6_1_what_is_node.html"><strong aria-hidden="true">6.1.</strong> What is Node?</a></li><li><a href="6_2_node_whats_our_plan.html"><strong aria-hidden="true">6.2.</strong> What's our plan</a></li><li><a href="6_3_node_the_main_loop.html"><strong aria-hidden="true">6.3.</strong> The main loop</a></li><li><a href="6_4_node_the_threadpool.html"><strong aria-hidden="true">6.4.</strong> The threadpool</a></li><li><a href="6_5_node_the_io_eventqueue.html"><strong aria-hidden="true">6.5.</strong> The I/O eventqueue</a></li><li><a href="6_6_node_final_code.html"><strong aria-hidden="true">6.6.</strong> Final code</a></li></ol></li><li><a href="conclusion.html">Conclusion</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar" class="menu-bar">
                    <div id="menu-bar-sticky-container">
                        <div class="left-buttons">
                            <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                                <i class="fa fa-bars"></i>
                            </button>
                            <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                                <i class="fa fa-paint-brush"></i>
                            </button>
                            <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                                <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                            </ul>
                            
                            <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                                <i class="fa fa-search"></i>
                            </button>
                            
                        </div>

                        <h1 class="menu-title">Investigating Async Basics - Implementing the Node.js Eventloop in Rust</h1>

                        <div class="right-buttons">
                            <a href="print.html" title="Print this book" aria-label="Print this book">
                                <i id="print-button" class="fa fa-print"></i>
                            </a>
                            
                        </div>
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#introduction" id="introduction">Introduction</a></h1>
<p>This book is part of a series investigating several aspects and methods of handling async code execution:</p>
<ul>
<li><a href="https://app.gitbook.com/@cfsamson/s/green-threads-explained-in-200-lines-of-rust/">Green threads explained in 200 lines of Rust</a></li>
<li>Investigating Async Basics by Implementing the Node.js Eventloop in Rust (The book you're reading now)</li>
<li>Investigating Epoll, Kqueue and IOCP with Rust (Will be released October 2. 2019)</li>
<li>Investigating Rusts Futures (TBD)</li>
</ul>
<p>Our main goal is to get a solid understanding of the inner secrets of Async code, using that knowledge to demystify Rusts Futures evolving async story.</p>
<h2><a class="header" href="#what-well-do" id="what-well-do">What we'll do</a></h2>
<ul>
<li>Go through the basics of asynchronous code execution, some history and basic definitions</li>
<li>Be very precise and define the difference between async and parallel</li>
<li>Talk about how the Operating System and the CPU in regards to I/O and async</li>
<li>Dig into how interrupts, scheduling, firmware and threads relate to our subject</li>
<li>Go through different methods of handling async, like green threads, threadpools and event queues</li>
<li>Look at how Nodes eventloop works and how it manages to be so efficient in execution async code</li>
<li>Implement our own working toy version of the Node.js eventloop using our knowledge</li>
</ul>
<h2><a class="header" href="#external-dependencies" id="external-dependencies">External dependencies</a></h2>
<p>We will only rely in the standard library for this, making sure that we understand everything and leave no gaps uncovered. While this is a pretty big constraint when using Rust it does require us to answer certain basic questions that would otherwise go unasked.</p>
<p>For this to work I had to make a library for the cross platform epoll/kqueue/IOCP eventloop that is explained in depth in the next book.</p>
<h2><a class="header" href="#disclaimer" id="disclaimer">Disclaimer</a></h2>
<ul>
<li>We'll implement a <strong>toy</strong> version of the Node.js eventloop (a bad, but working and conceptually similar eventloop)</li>
<li>We'll not primarily focus on code quality and safety, though this is important, we want to understand the concepts and ideas behind the code. We will have to take many shortcuts to keep this concise and short. If we don't we end up reimplementing <code>libuv</code> at some point :)</li>
<li>I will however do my best to point out hazards and the shortcuts we make. I will try to point out obvious places we could do a better job, and I will not use <code>unsafe</code> needlessly unless there is a very good reason to do it.</li>
<li>The book(s) you're reading is the result of a few hundred hours of investigations. I will not claim expertise beyond that, but I will guarantee that I try to verify all the information from more than one source unless it's directly from official documentation.</li>
</ul>
<h2><a class="header" href="#why-i-write-this" id="why-i-write-this">Why I write this</a></h2>
<p>I'm curious, and I really hate the feeling of having big gaps in my understanding of a subject. I initially wanted to write a short article about async code and tie it in to Rust Futures. As I started digging and uncover the gaps I had, that idea for an article have expanded into 4 small books on the subject.</p>
<p>Now, some of this information and insight is hard to come by, so I write it down in these books and share my findings with everyone else. I hope you find it as interesting as me.</p>
<h1><a class="header" href="#what-is-asynchronous-code-execution-and-concurrency" id="what-is-asynchronous-code-execution-and-concurrency">What is asynchronous code execution and concurrency?</a></h1>
<p>Concurrency is about <strong>dealing</strong> with a lot of things at the same time. Rob Pike
defines this as &quot;the composition of independently executed processes.&quot;</p>
<p>Parallelism is about <strong>doing</strong> a lot of things at the same time.</p>
<p>We handle concurrency by executing tasks/processes in an asynchronous manner. 
Asynchronous code execution is therefore the way we handle concurrency in programming.</p>
<h2><a class="header" href="#lets-start-off-with-some-definitions" id="lets-start-off-with-some-definitions">Lets start off with some definitions</a></h2>
<h3><a class="header" href="#resource" id="resource">Resource</a></h3>
<p>Something we need to perform work on a task. Our resources is limited.</p>
<h3><a class="header" href="#progressing-a-task" id="progressing-a-task">Progressing a task</a></h3>
<p>Perform work that requires some kind of resource, whether it's computational power 
from the CPU or it's your brain using its processing power to process something. </p>
<h3><a class="header" href="#parallel" id="parallel">Parallel</a></h3>
<p>Something happening independently at the <strong>exact</strong> same time.</p>
<h3><a class="header" href="#concurrent" id="concurrent">Concurrent</a></h3>
<p>Tasks that are &quot;in progress&quot; at the same time, but not neccicarely progressing
simultaneously. In computer programming this most often implies that the 
tasks which run concurrently can be stopped and resumed. </p>
<h3><a class="header" href="#reference-frame" id="reference-frame">Reference frame</a></h3>
<p>The frame of reference when we use when we define what we operate concurrent relative
to. Most often it's the tasks we control in our process, but as you'll see, not
being aware that it's important that we use the same reference frame can cause 
some confusion.</p>
<h2><a class="header" href="#the-mental-model-i-use" id="the-mental-model-i-use">The mental model I use.</a></h2>
<p>I firmly believe the main reason we find parallel and concurrent programming hard to reason about is that it's very easy to 
confuse parallel execution with concurrent execution. I think that most of this confusion stems from how we tend to 
model events in our everyday life. We tend to not define these terms very precise so our intuition 
is often wrong. </p>
<blockquote>
<p>It doesn't help that <strong>concurrent</strong> is defined in the dictionary as: <em>operating or occurring at the same time</em> which 
doesn't really help us much when trying to describe how it differs from <strong>parallel</strong></p>
</blockquote>
<p><strong>Let's model our world with these simple rules:</strong></p>
<ol>
<li>Everything you do requires resources</li>
<li>Resources are limited and/or timing is important</li>
<li>Our main purpose is to use resources as efficiently as possible</li>
<li>Waiting is performing work, however it's useless work</li>
<li>Resources are limited</li>
</ol>
<p>Now, all of these need to be true for concurrency to even matter, but this is 
true from on perspective or another more often than you'd think. Even in the 
simple case that your server or computer has more than enough resources, you still
waste energy if you're inefficient or your users might wait longer then they should.</p>
<h3><a class="header" href="#parallelism" id="parallelism">Parallelism</a></h3>
<p>Is increasing the resources we use to solve a task. It has nothing to do with efficiency.</p>
<h3><a class="header" href="#concurrency" id="concurrency">Concurrency</a></h3>
<p>Has everything to do with efficiency and resource utilization. Concurrency can never make <em>one single task go faster</em>. 
It can only help us utilize our resources better and thereby <em>finish a set of tasks faster</em>.</p>
<h3><a class="header" href="#lets-draw-some-parallels-to-process-economics" id="lets-draw-some-parallels-to-process-economics">Let's draw some parallels to process economics</a></h3>
<p>In businesses that manufacture goods, we often talk about LEAN processes. And this is pretty easy to compare with what concurrency
does for programmers. I'll let let this 3 minute video explain it for me:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Oz8BR5Lflzg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>This very modern video might not make you a LEAN expert, but it does explain some
of the gains we try to achieve when applying LEAN techniques, amongst those: 
eliminate waiting and non-value-adding tasks.</p>
<blockquote>
<p>In programming we could say that we want to avoid <code>blocking</code> and <code>polling</code> in a busy loop.</p>
</blockquote>
<p>Now would adding more resources (more workers) help in this case? Yes, but we use double the resources to produce the 
same output as 1 person with a optimal process could do. That's not optimal utilization of our resources.</p>
<blockquote>
<p>To continue our metaphor, we could say that we could solve the problem of a freezing UI while waiting for an I/O event to occur 
by using a new thread and <code>poll</code>in a loop or <code>block</code> there instead. However, that thread is either consuming resources doing
nothing or worse, using one core to busy loop while checking if an event is ready. Either way it's not optimal, especially
if you run a server you want to utilize fully.</p>
</blockquote>
<p>If you consider the coffee machine as some I/O resource, we would like to start that process, then move on to preparing the 
next job, or do other work that needs to be done instead of waiting.</p>
<p>But that means there are things happening in parallel here? Yes, the coffee machine is doing work while the &quot;worker&quot; is doing
maintenance and filling water. But this is the crux: Our reference frame is the worker, not the whole system. The worker
is doing things concurrently. The guy making coffee (the worker) is your code. </p>
<p><strong>Concurrency is about working smarter and harder. Parallelism is throwing more resources at the problem</strong></p>
<h2><a class="header" href="#concurrency-and-its-relation-to-io" id="concurrency-and-its-relation-to-io">Concurrency and its relation to I/O</a></h2>
<p>As you might understand from what I've written so far, writing async code mostly
makes sense when you need to be smart to make optimal use of your resources.</p>
<p>Now if you're code is working hard to solve a problem, there often is no help
in concurrency, this is where parallelism comes in to play since it gives you
a way to throw more resources at the problem if you can split it into parts that
you can work on in parallel.</p>
<p><strong>I can see two major use cases for concurrency:</strong></p>
<ol>
<li>When performing I/O and you need to wait for some external event to occur</li>
<li>When you need to divide your attention and prevent one task from waiting too 
long</li>
</ol>
<p>The first is the classic I/O example, where you will have to wait for a network
call, a file operation or something else to happen before you can progress one 
task, but you have many tasks to do so instead of waiting you continue work 
elsewhere and either check in regularly to see if the task is ready to progress
or make sure you are notified when that task is ready to progress.</p>
<p>The second is an example that is often the case when having an UI. Let's pretend
you only have one core. How do you prevent the whole UI from becoming unresponsive
while performing other CPU intensive tasks?</p>
<p>Well, you can stop what ever task you're doing every 16ms, and run the &quot;update UI&quot;
task, and then resume whatever you were doing afterwards. This way, you will have
to stop/resume your task 60 times a second, but you will also have a fully 
responsive UI which has roughly a 60 Hz refresh rate.</p>
<h2><a class="header" href="#what-about-threads" id="what-about-threads">What about threads</a></h2>
<p>We'll cover threads a bit more when we talk about operating systems, but I'll mention them here as well. The problem with
threads provided by the operating system is that they appear to be mapped to cores. But that is not neccicarely the truth even 
though most operating systems will try to map one thread to a core up to the number of threads is equal to  the number of cores.</p>
<p>Once we create more threads than there are cores, the OS will switch between our threads and progress each of them concurrently
using the scheduler to give each thread some time to run. So in this way, threads can be a means to achieve parallelism, but 
they can also be a means to achieve concurrency. Now if you find that confusing, I understand. There is a reason why this is 
hard to understand. </p>
<p>But it's a good time to talk about changing the reference frame.</p>
<h2><a class="header" href="#changing-the-reference-frame" id="changing-the-reference-frame">Changing the reference frame</a></h2>
<p>When you write code that is perfectly synchronous from your perspective, let's take a look at how that looks from the operating
system perspective.</p>
<p>The Operating System might not run your code from start to end at all. It might stop and resume your process many times. 
The CPU might get interrupted and handle som inputs while you think it's only focused on your task. So synchronous execution is
only an illusion. But from the perspective of you as a programmer it's not, and that is the important takeaway:</p>
<p>When we talk about concurrency without providing any other context we are using you as a programmer and your code 
(your process) as the reference frame.</p>
<p>The reason I spend so much time on this is that once you realize that, you'll start to see that some of the things you hear and
learn that might seem contradicting really is not. You'll just have to consider the reference frame first.</p>
<p>If this sounds complicated, I promise that we'll get to see and know this better as we go on. So if you found this confusing, relax
this will become clearer as we go on.</p>
<h1><a class="header" href="#async-history" id="async-history">Async history</a></h1>
<p>In the beginning.
Everything was synchronous. Computers had one CPU and it executed a piece of code written by a programmer and then returned. No scheduling, no threads, no multitasking. We're talking back when the days where a program looked like this:</p>
<p><img src="./images/punched_card_deck.jpg" alt="Image" /></p>
<p>There were operating systems though, and when personal computing started to grow in the 80's we had operating systems like DOS, but they usually yielded control of the entire CPU to the program (and the programmer) that was currently running.
This worked fine, but as interactive UI's using a mouse and windowed operating systems became the norm, this simply couldn't work anymore.</p>
<h2><a class="header" href="#hyperthreading" id="hyperthreading">Hyperthreading</a></h2>
<p>As CPU's evolved and added more functionality like several ALUs (Algorithmic Logical Unit) and more logical units in general, the CPU manufacturers realized that the entire CPU was never utilitized fully. For example when an operation only required some parts of the CPU, an instruction could be run on the ALU simultainiously. This became the start of Hyperthreading.¨</p>
<p>You see, on your computer today that it has i.e. 6 cores, and 12 logical cores. This is exactly where Hyperthreading comes in. It &quot;simulates&quot; two cores on the same core by using unused parts of the CPU to drive progress on thread &quot;2&quot; simultainiously as it's running the code on thread &quot;1&quot; by using a number of smart tricks (like the one with the ALU). Now we could actually offload some work on one thread while keeping the UI interactive by responding to events in the second thread event though we only have one CPU core.</p>
<p>You might wonder how this is really different from multicore processors? What about performance? I turns out that Hyperthreading has been improved since the 90's all the time. Since you're not actually running two CPU's there will be some operations that need to wait for each other to finish, and how much of a penalty this gives compared to two seperate cores might depend a bit on exactly what the code is doing, but the numbers I have seen shows &quot;only&quot; a 30 % penalty comparted to two seperate CPU's. In other words, it's pretty good!</p>
<h2><a class="header" href="#non-preemptive-multitasking" id="non-preemptive-multitasking">Non-preemptive multitasking</a></h2>
<p>The method used to be able to keep the UI interactive and running background processes, was accomplished by non-preemtive multitasking. This kind of multitasking put the responsibility of letting the OS run other tasks like responding to input from the mouse, or running a background task in the hands of the programmer. Typically the programmeryieldedcontrol to the OS.</p>
<p>Beside offloading a huge responsibility to every programmer writing a program for your platform, this was also error prone. A small mistake in a programs code could halt or crash the entire system. If you remember Windows 95, you also remember the times when a window hung and you could paint the entire screen with it (almost the same way as the end in Solitare, the card game that came with Windows). This was a typical error in the code that was supposed to yield control to the operating system.</p>
<p>If you're not sure about what this is I can recommend my previous book that explains this part of multitasking pretty well. You'll know everything you need about threads, contexts, stacks and scheduling for following along.</p>
<h2><a class="header" href="#preemtive-multitasking" id="preemtive-multitasking">Preemtive multitasking</a></h2>
<p>While non-preemtive multitasking sounded like a good idea, it turned out to create serious problems as well. I will not list them here but as you can imagine, letting every program and programmer out there be responsible for parts of the scheduling of tasks in an operating system will be chaos and ultimately lead to a bad user experience.
So they put the responsibility of scheduling the CPU resources between the programs that requested it (including to OS itself) in the hands of the OS. The OS can stop execution of a process, do something else, and switch back.</p>
<p>In a single core machine you can visualize this as running a program you wrote, and the OS stops to update the mouse position, and witches back to your program. This can happen many times each second, not only to keep the UI responsive but it can also give some time to other background tasks and IO events.</p>
<p>This is now the prevailing way to design an operating system. </p>
<h2><a class="header" href="#so-how-synchronous-is-the-code-you-write-really-" id="so-how-synchronous-is-the-code-you-write-really-">So how synchronous is the code you write, really ?</a></h2>
<p>As many things this depends on your perspective. From the perspective of the code you write, and you as a programmer, everything will happen in the order you write it.
From the OS perspective it might, or might not, interrupt your code, pause it and run some other code in the meantime before resuming. 
From the perspective of the CPU it will mostly execute* instructions one at a time. They don't care who wrote the code though so when a hardware interrupt happens, they will immediately stop and give control to an interrupt handler, so the CPU doesn't have any concept of asynchronous execution.</p>
<p>However, modern CPU can also do a lot if things in parallel. Most CPUs are pipelined, meaning that the next instruction is loaded while the current is executing. It might have a branch predictor that tries to figure out what instructions to load next. The processor can also reorder instructions by using &quot;out of order execution&quot; if it believes it makes things faster this way without &quot;asking&quot; or &quot;telling&quot; the programmer or the OS so you might not have any guarantee that A happens before B. The CPU offloads some work to separate &quot;coprocessors&quot; like the FPU for for floating point calculations leaving the main CPU ready to do other tasks et cetera.
*As a high level overview, it's OK to model the CPU as operating in a synchronous manner, but lets for now just make a mental note that this is a model with a ton caveats that becomes especially important when talking about parallelism, synchronization primitives like mutexes and atomics and security.</p>
<h1><a class="header" href="#the-operating-system" id="the-operating-system">The Operating System</a></h1>
<p>The operating system stands in the center of everything we do as programmers, so there is no way for us to discuss any kind 
of fundamentals in programming without talking about operating systems in a bit of detail. But since we rely on the 
operating system as much as we usually do when performing I/O operations we'll have to learn how to communicate with the
OS.</p>
<h2><a class="header" href="#concurrency-from-the-operating-systems-perspective" id="concurrency-from-the-operating-systems-perspective">Concurrency from the operating systems perspective</a></h2>
<h2><a class="header" href="#writing-cross-platform-abstractions" id="writing-cross-platform-abstractions">Writing cross platform abstractions</a></h2>
<p>If you isolate the code needed only for Linux and Macos you'll see that it's not many lines of code to write. But once you
want to make a cross platform variant, the amount of code explodes. This is a problem when writing about this stuff in general,
but we need some basic understanding on how the different operating systems work under the covers. </p>
<p>My experience in general is that Linux and Macos have simpler api's requiring fewer lines of code, and often (but not always) 
the exact same call works for both systems.</p>
<p>Windows on the other hand is mor complex, requires more &quot;magic&quot; constant numbers, requires you to set up more structures to pass in, 
and way more lines of code. What Windows does have though are very good documentation so even though it's more work you'll also 
find more official documentation.</p>
<p>This is why the Rust community (and other languages often has something similar) gathers around crates like <a href="https://github.com/rust-lang/libc">libc</a> 
which already have defined most methods and constants you need.</p>
<h1><a class="header" href="#threads" id="threads">Threads</a></h1>
<p>Threads are one of the baisc constructs for running code that we programmers create. Like the syscall for outputting text to the console, 
there is a syscall for asking the OS to create a thread. </p>
<p>Now threads are a bit special, since they are the thing that actually makes us think that we write <strong>synchronous</strong> code at all.</p>
<p>Let's stop for a second and think a bit about the significance of threads for our the problem domain we're investigating here:</p>
<p>The &quot;naive&quot; way of thinking about your code is like this:</p>
<p>Now threads</p>
<p>memory</p>
<p>faking sync</p>
<h2><a class="header" href="#communicating-with-the-operating-system" id="communicating-with-the-operating-system">Communicating with the operating system</a></h2>
<p>Communication with the operating system is done through <code>System Calls</code> or 
&quot;syscalls&quot;, this is a public API that the operating system provides for 
applications to work. Most of the time these calls are abstracted away for us as 
programmers by the language or the runtime we use. A language like Rust makes it 
trivial to make a syscall though which we will see below.</p>
<p>Now syscalls is an example of something that is absolutely non-portable, but 
often (not always) BSD-family operating systems uses the same syscalls as 
Linux-family of operating system. Often these are referred to as UNIX family of 
operating systems.</p>
<p>Windows on the other hand has nothing in common with the UNIX family and uses 
it's own api, often referred to as WinAPI.</p>
<h3><a class="header" href="#syscall-example" id="syscall-example">Syscall example</a></h3>
<p>To get a bit more familiar with syscalls we'll implement a very basic one for 
the three arcitectures: BSD(macos), Linux and Windows.</p>
<p>The syscall we'll implement is the one used when we write something to <code>stdout</code> 
since that is such a common operation it's interesting to se how it really works:</p>
<p>Fortunately for us in this specific example, the syscall is the same on Linux 
and on Macos so we only need to worry if we're on Windows and therefore use the 
<code>#[cfg(not(target_os = &quot;windows&quot;))]</code> conditional compilation flag. For the 
Windows syscall we do the opposite.</p>
<h4><a class="header" href="#a-cross-platform-write-syscall" id="a-cross-platform-write-syscall">A cross platform Write syscall</a></h4>
<p>You can run this code directly here in the window. However, the Rust playground 
runs on Linux, you'll need to copy the code over to a Windows machine if you 
want to try it out the code for Windows further down.</p>
<pre><pre class="playpen"><code class="language-rust">use std::io;

fn main() {
    let sys_message = String::from(&quot;Hello world from syscall!\n&quot;);
    syscall(sys_message).unwrap();
}

// and: http://man7.org/linux/man-pages/man2/write.2.html
#[cfg(not(target_os = &quot;windows&quot;))]
#[link(name = &quot;c&quot;)]
extern &quot;C&quot; {
    fn write(fd: u32, buf: *const u8, count: usize) -&gt; i32;
}

#[cfg(not(target_os = &quot;windows&quot;))]
fn syscall(message: String) -&gt; io::Result&lt;()&gt; {
    let msg_ptr = message.as_ptr();
    let len = message.len();
    let res = unsafe { write(1, msg_ptr, len) };

    if res == -1 {
        return Err(io::Error::last_os_error());
    }
    Ok(())
}

</code></pre></pre>
<p>I'll explain what we just did here. I assume that the <code>main</code> method needs no 
comment.</p>
<h4><a class="header" href="#linux-and-macos" id="linux-and-macos">Linux and Macos</a></h4>
<pre><code class="language-rust no_run noplaypen">#[link(name = &quot;c&quot;)]
</code></pre>
<p>Every Linux installation comes with a version of <code>libc</code> which a C-library for 
communicating with the operating system. Having a <code>libc</code> with a consistent API 
means they can change the underlying implementation without braking everyones 
code. This flag tells the compiler to link to the &quot;c&quot; library on the system we'
re compiling for.</p>
<pre><code class="language-rust no_run noplaypen">extern &quot;C&quot; {
    fn write(fd: u32, buf: *const u8, count: usize);
}
</code></pre>
<p><code>extern &quot;C&quot;</code> or only <code>extern</code> (C is assumed if nothing is specified) means we're 
linking to specific functions in the &quot;c&quot; library using the &quot;C&quot; calling 
convention. As you'll see on Windows we'll need to change this since it uses a 
different calling convention than the UNIX family.</p>
<p>The function we're linking to needs to have the exact same name, in this case 
<code>write</code>. The parameters doesn't need to have the same name but they must be in 
the right order and it's good practice to name them the same as in the library 
you're linking to.</p>
<p>The write function takes a <code>file descriptor</code> which in this case is a handle to 
<code>stdout</code>, a pointer to a array of <code>u8</code> values, and a count of how many values we 
want to read from the buffer.</p>
<pre><code class="language-rust no_run noplaypen">#[cfg(not(target_os = &quot;windows&quot;))]
fn syscall_libc(message: String) {
    let msg_ptr = message.as_ptr();
    let len = message.len();
    unsafe { write(1, msg_ptr, len) };
}
</code></pre>
<p>The first thing we do is to get the pointer to the underlying buffer for our 
string. That will be a pointer of type <code>*const u8</code> which matches our <code>buf</code> 
argument. The length of the message corresponds to the <code>count</code> argument.</p>
<p>You might ask how we know that <code>1</code> is the file handle to <code>stdout</code> and where we 
found that value. You'll notice this a lot when writing syscalls from Rust. 
Usually constants are defined in the C header files which we can't link to, so 
we need to search them up. 1 is always the file descriptor for <code>stdout</code> on UNIX 
systems.</p>
<p>A call to a FFI function is always unsafe so we need to use the <code>unsafe</code> keyword 
here.</p>
<h3><a class="header" href="#syscall-on-windows" id="syscall-on-windows">Syscall on Windows</a></h3>
<pre><code class="language-rust no_run noplaypen">use std::io;

fn main() {
    let sys_message = String::from(&quot;Hello world from syscall!\n&quot;);
    syscall(sys_message).unwrap();
}

#[cfg(target_os = &quot;windows&quot;)]
#[link(name = &quot;kernel32&quot;)]
extern &quot;stdcall&quot; {
    /// https://docs.microsoft.com/en-us/windows/console/getstdhandle
    fn GetStdHandle(nStdHandle: i32) -&gt; i32;
    /// https://docs.microsoft.com/en-us/windows/console/writeconsole
    fn WriteConsoleW(
        hConsoleOutput: i32,
        lpBuffer: *const u16,
        numberOfCharsToWrite: u32,
        lpNumberOfCharsWritten: *mut u32,
        lpReserved: *const std::ffi::c_void,
    ) -&gt; i32;
}

#[cfg(target_os = &quot;windows&quot;)]
fn syscall(message: String) -&gt; io::Result&lt;()&gt; {

    // let's convert our utf-8 to a format windows understands
    let msg: Vec&lt;u16&gt; = message.encode_utf16().collect();
    let msg_ptr = msg.as_ptr();
    let len = msg.len() as u32;
    
    let mut output: u32 = 0;
        let handle = unsafe { GetStdHandle(-11) };
        if handle  == -1 {
            return Err(io::Error::last_os_error())
        }

        let res = unsafe { 
            WriteConsoleW(handle, msg_ptr, len, &amp;mut output, std::ptr::null()) 
            };
        if res  == 0 {
            return Err(io::Error::last_os_error());
        }

    assert_eq!(output as usize, len);
    Ok(())
}
</code></pre>
<pre><code>The Rust playground, which we use to run our code, is a Linux machine. I 
disabled the possibility to run the windows code here (since it will 
essentially just be skipped on compilation). However, if you have a Windows 
machine, copy the code above and try for yourself.
</code></pre>
<p>Now, just by looking at the code above you see it starts to get a bit more 
complex, but let's spend som time to go through line by line what we do here as 
well.</p>
<pre><code class="language-text">#[cfg(target_os = &quot;windows&quot;)]
#[link(name = &quot;kernel32&quot;)]
</code></pre>
<p>The first line is just telling the compiler to only compile this if the 
<code>target_os</code> is Windows.</p>
<p>The second line is a linker directive, telling the linker we want to link to the 
library <code>kernel32</code> (if you ever see an example that links to <code>user32</code> that will 
also work).</p>
<pre><code class="language-rust no_run noplaypen">extern &quot;stdcall&quot; {
    /// https://docs.microsoft.com/en-us/windows/console/getstdhandle
    fn GetStdHandle(nStdHandle: i32) -&gt; i32;
    /// https://docs.microsoft.com/en-us/windows/console/writeconsole
    fn WriteConsoleW(
        hConsoleOutput: i32,
        lpBuffer: *const u16,
        numberOfCharsToWrite: u32,
        lpNumberOfCharsWritten: *mut u32,
        lpReserved: *const std::ffi::c_void,
    ) -&gt; i32;
}
</code></pre>
<p>First of all, <code>extern &quot;stdcall&quot;</code>, tells the compiler that we won't use the <code>C</code> 
calling convention but use Windows calling convention called <code>stdcall</code>.</p>
<p>The next part is the functions we want to link to. On Windows, we need to link 
to two functions to get this to work: <code>GetStdHandle</code> and <code>WriteConsoleA</code>. 
<code>GetStdHandle</code> retrieves a reference to a standard device like <code>stdout</code>.</p>
<p>WriteConsole comes in two flavors, <code>WriteConsoleW</code> that takes in Unicode text 
and <code>WriteConsoleA</code> that takes ANSI encoded text. </p>
<p>Now, ANSI encoded text works fine if you only write English text, but as soon as 
you write text in other languages you might need to use special characters that 
are not possible to represent in <code>ANSI</code> but is possible in <code>utf-8</code> and our code 
will break.</p>
<p>That's why we'll convert our <code>utf-8</code> encoded text to <code>utf-16</code> encoded Unicode 
text that can represent these characters and use the <code>WriteConsoleW</code> function.</p>
<pre><code class="language-rust no_run noplaypen">#[cfg(target_os = &quot;windows&quot;)]
fn syscall(message: String) -&gt; io::Result&lt;()&gt; {

    // let's convert our utf-8 to a format windows understands
    let msg: Vec&lt;u16&gt; = message.encode_utf16().collect();
    let msg_ptr = msg.as_ptr();
    let len = msg.len() as u32;
    
    let mut output: u32 = 0;
        let handle = unsafe { GetStdHandle(-11) };
        if handle  == -1 {
            return Err(io::Error::last_os_error())
        }

        let res = unsafe { 
            WriteConsoleW(handle, msg_ptr, len, &amp;mut output, std::ptr::null()) 
            };

        if res  == 0 {
            return Err(io::Error::last_os_error());
        }

    assert_eq!(output, len);
    Ok(())
}
</code></pre>
<p>The first thing we do is to convert the text to utf-16 encoded text which 
Windows uses. Fortunately Rust has a built in function to encode our <code>utf-8</code>
encoded text to <code>utf-16</code> code points. <code>encode_utf16</code> returns an iterator over 
<code>u16</code> code points that we can collect to a <code>Vec</code>.</p>
<pre><code class="language-rust no_run noplaypen">let msg: Vec&lt;u16&gt; = message.encode_utf16().collect();
let msg_ptr = msg.as_ptr();
let len = msg.len() as u32;
</code></pre>
<p>We then get the pointer to the underlaying buffer of our <code>Vec</code> and calculate the 
length.</p>
<pre><code class="language-rust no_run noplaypen">let handle = unsafe { GetStdHandle(-11) };
   if handle  == -1 {
       return Err(io::Error::last_os_error())
   }
</code></pre>
<p>The next is a call to <code>GetStdHandle</code>. We pass in the value <code>-11</code>. The values we 
need to pass in for the different standard devices is actually documented 
together with the <code>GetStdHandle</code> documentation:</p>
<ul>
<li>Stdin: -10</li>
<li>Stdout: -11</li>
<li>StdErr: -12</li>
</ul>
<p>Now, we're lucky here, it's not that common that we find this information 
together with the documentation function we call but it's very convenient when 
we do.</p>
<p>What return codes to expect is also documented thoroughly so we handle potential 
errors here in the same way as we did for the Linux/Macos syscalls.</p>
<pre><code class="language-rust no_run noplaypen">let res = unsafe { 
    WriteConsoleW(handle, msg_ptr, len, &amp;mut output, std::ptr::null()) 
    };

if res  == 0 {
    return Err(io::Error::last_os_error());
}
</code></pre>
<p>Next up is the call to the <code>WriteConsoleW</code> function. Now that we have explained 
everything else there is nothing too fancy about this.</p>
<h3><a class="header" href="#a-note-about-complexity" id="a-note-about-complexity">A note about complexity</a></h3>
<p>There is a lot of &quot;hidden&quot; complexity when writing cross platform code at this 
level. One hurdle is to get something working, which can prove to be quite a 
challenge. Getting it to work <strong>correctly</strong> and <strong>safely</strong> while covering edge 
cases is an additional challenge. </p>
<p>Are we 100% sure that all valid <code>utf-8</code> code points which we use in Rust is valid 
<code>utf-16</code> encoded Unicode that Windows will display correctly?</p>
<p>I think so, but being 100 % sure about <a href="https://en.wikipedia.org/wiki/Comparison_of_Unicode_encodings">this might not be as easy as one might think</a>.</p>
<h1><a class="header" href="#our-finished-cross-platform-syscall" id="our-finished-cross-platform-syscall">Our finished cross platform syscall</a></h1>
<pre><pre class="playpen"><code class="language-rust">use std::io;

fn main() {
    let sys_message = String::from(&quot;Hello world from syscall!\n&quot;);
    syscall(sys_message).unwrap();
}

// and: http://man7.org/linux/man-pages/man2/write.2.html
#[cfg(not(target_os = &quot;windows&quot;))]
#[link(name = &quot;c&quot;)]
extern &quot;C&quot; {
    fn write(fd: u32, buf: *const u8, count: usize) -&gt; i32;
}

#[cfg(not(target_os = &quot;windows&quot;))]
fn syscall(message: String) -&gt; io::Result&lt;()&gt; {
    let msg_ptr = message.as_ptr();
    let len = message.len();
    let res = unsafe { write(1, msg_ptr, len) };

    if res == -1 {
        return Err(io::Error::last_os_error());
    }
    Ok(())
}

#[cfg(target_os = &quot;windows&quot;)]
#[link(name = &quot;kernel32&quot;)]
extern &quot;stdcall&quot; {
    /// https://docs.microsoft.com/en-us/windows/console/getstdhandle
    fn GetStdHandle(nStdHandle: i32) -&gt; i32;
    /// https://docs.microsoft.com/en-us/windows/console/writeconsole
    fn WriteConsoleW(
        hConsoleOutput: i32,
        lpBuffer: *const u16,
        numberOfCharsToWrite: u32,
        lpNumberOfCharsWritten: *mut u32,
        lpReserved: *const std::ffi::c_void,
    ) -&gt; i32;
}

#[cfg(target_os = &quot;windows&quot;)]
fn syscall(message: String) -&gt; io::Result&lt;()&gt; {

    // let's convert our utf-8 to a format windows understands
    let msg: Vec&lt;u16&gt; = message.encode_utf16().collect();
    let msg_ptr = msg.as_ptr();
    let len = msg.len() as u32;

    let mut output: u32 = 0;
        let handle = unsafe { GetStdHandle(-11) };
        if handle  == -1 {
            return Err(io::Error::last_os_error())
        }

        let res = unsafe { 
            WriteConsoleW(handle, msg_ptr, len, &amp;mut output, std::ptr::null()) 
            };

        if res  == 0 {
            return Err(io::Error::last_os_error());
        }

    assert_eq!(output, len);
    Ok(())
}
</code></pre></pre>
<p>I find it easy to forget is that everything I do goes through the operating system. Of course I know it's there, .</p>
<p>When we ask for memory, like if we call <code>let my_vec = vec![0_u8;1040]</code> we actually ask the OS to map some memory for us and hand it over. </p>
<p>Have you ever wondered how you can write plain assembly, which pretty much is CPU instructions, and execute them, but still get an error if you try to access memory that is not mapped to you?</p>
<p>Let's say you execute the following code:</p>
<pre><pre class="playpen"><code class="language-rust">#![feature(asm)]
fn main() {
    let t = 100;
    let x = dereference(&amp;t);
    
    println!(&quot;{}&quot;, x);
}

fn dereference(ptr: *const usize) -&gt; usize {
    let res: usize;
    unsafe {
    // Note: the parenthesis around ($1) means that we want to get the value at 
    // the memory location which $1 is pointing at
    asm!(&quot;mov ($1), $0&quot;:&quot;=r&quot;(res): &quot;r&quot;(ptr));
    }
 
    res
}
</code></pre></pre>
<p>As you see, this code will output <code>100</code> as expected. But let's instead create a pointer with the address <code>9999999</code> which
we know just points somewhere random and see what happens when we pass that into the same function:</p>
<pre><pre class="playpen"><code class="language-rust">#![feature(asm)]
fn main() {
    let t = 9999999 as *const usize;
    let x = dereference(t);
    
    println!(&quot;{}&quot;, x);
}
#
# fn dereference(ptr: *const usize) -&gt; usize {
#     let res: usize;
#     unsafe {
#     asm!(&quot;mov ($1), $0&quot;:&quot;=r&quot;(res): &quot;r&quot;(ptr));
#     }
#  
#     res
# }
</code></pre></pre>
<p>Now we get a segmentation fault. Not very surprising, and a complicated way of dereferencing a pointer but I wanted to stress 
that we're &quot;talking&quot; directly with the CPU here. There are no checks in Rust, no syscalls or anything happening behind the 
scenes that alerst the OS that we try to access memory we shouldn't access. So how does the CPU know that we can't access this memory location?</p>
<p>This is a sure hint that the CPU does indeed operate in tandem with the operating system, we ask the operating system to map some
memory for us, and somehow the CPU (MMU) know what memory we can access and not.</p>
<h1><a class="header" href="#bonus-section" id="bonus-section">Bonus section</a></h1>
<p>So how does the CPU know that we don't have access to the memory referenced in the example above?</p>
<p>Most CPU's ca run in different memory protection levels.</p>
<h1><a class="header" href="#interrupts-firmware-and-io" id="interrupts-firmware-and-io">Interrupts, Firmware and I/O</a></h1>
<h1><a class="header" href="#strategies-for-handling-io" id="strategies-for-handling-io">Strategies for handling I/O</a></h1>
<h1><a class="header" href="#implementing-the-node-eventloop" id="implementing-the-node-eventloop">Implementing the Node Eventloop</a></h1>
<h1><a class="header" href="#what-is-node" id="what-is-node">What is Node?</a></h1>
<h1><a class="header" href="#whats-our-plan" id="whats-our-plan">What's our plan</a></h1>
<h1><a class="header" href="#the-main-loop" id="the-main-loop">The main loop</a></h1>
<h1><a class="header" href="#the-threadpool" id="the-threadpool">The threadpool</a></h1>
<h1><a class="header" href="#the-io-eventqueue" id="the-io-eventqueue">The I/O eventqueue</a></h1>
<h1><a class="header" href="#final-code" id="final-code">Final code</a></h1>
<h1><a class="header" href="#conclusion" id="conclusion">Conclusion</a></h1>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
